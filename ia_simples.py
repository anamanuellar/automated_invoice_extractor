import streamlit as st
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from datetime import datetime
from sklearn.ensemble import IsolationForest
import warnings
warnings.filterwarnings('ignore') # Ignorar avisos do sklearn e pandas

# =============== 1. FUN√á√ïES DE INTELIG√äNCIA ARTIFICIAL ===============

# Simula√ß√£o da Fun√ß√£o de Classifica√ß√£o (mantida para evitar depend√™ncia externa)
def classify_expense_hf(text: str) -> Dict[str, Any]:
    """Simula a classifica√ß√£o de despesa por um modelo Hugging Face."""
    # Simula√ß√£o para evitar quebra no c√≥digo, j√° que n√£o temos o modelo real
    text_lower = text.lower()
    
    if "cloud" in text_lower or "ec2" in text_lower or "azure" in text_lower:
        categoria = "Infraestrutura de TI"
    elif "licen√ßa" in text_lower or "software" in text_lower or "office" in text_lower:
        categoria = "Software e Licen√ßas"
    elif "passagem" in text_lower or "hotel" in text_lower:
        categoria = "Viagens e Deslocamentos"
    else:
        categoria = "Outros Servi√ßos"
        
    return {
        "status": "OK",
        "categoria": categoria,
        "confianca": 0.85, # Confian√ßa simulada
        "alternativas": {"Administrativo": 0.10, "Marketing": 0.05}
    }

# Simula√ß√£o da Fun√ß√£o de An√°lise de Risco (mantida)
def analyze_supplier_risk(cnpj: Optional[str]) -> Dict[str, Any]:
    """Simula a an√°lise de risco de um fornecedor pelo CNPJ."""
    if cnpj and '0001' in cnpj:
        score = np.random.uniform(0.7, 0.95)
        risco = "Baixo" if score > 0.85 else "M√©dio"
    else:
        score = np.random.uniform(0.5, 0.7)
        risco = "M√©dio" if score > 0.6 else "Alto"
        
    return {
        "risco_score": round(score, 2),
        "risco_nivel": risco,
        "detalhes": "Consulta de situa√ß√£o fiscal e sa√∫de financeira (Simulado)."
    }

# Simula√ß√£o da Fun√ß√£o de Previs√£o (mantida)
def simple_forecast(df: pd.DataFrame) -> pd.DataFrame:
    """Simula uma previs√£o simples (m√©dia m√≥vel) para os pr√≥ximos 3 meses."""
    if df.empty or 'data_emissao' not in df.columns or 'valor_total_num' not in df.columns:
        return pd.DataFrame()
        
    df = df.copy()
    df['data_emissao'] = pd.to_datetime(df['data_emissao'], format="%d/%m/%Y", errors='coerce')
    df.dropna(subset=['data_emissao', 'valor_total_num'], inplace=True)
    
    # Agrupa por m√™s e calcula a m√©dia
    df_mensal = df.set_index('data_emissao')['valor_total_num'].resample('M').sum()
    
    # Simula√ß√£o de M√©dia M√≥vel Simples
    rolling_avg = df_mensal.tail(3).mean() # M√©dia dos √∫ltimos 3 meses
    
    ultima_data = df_mensal.index[-1]
    datas_futuras = pd.date_range(start=ultima_data + pd.Timedelta(days=1), periods=3, freq='M')
    
    previsoes = pd.DataFrame({
        'M√™s': datas_futuras.strftime('%Y-%m'),
        'Valor Previsto (R$)': rolling_avg * np.random.uniform(0.9, 1.1) # Adiciona um ru√≠do simulado
    })
    
    return previsoes

# ================= 2. NOVA FUN√á√ÉO: DETEC√á√ÉO DE ANOMALIAS =================

def detect_anomalies_isolation_forest(df: pd.DataFrame) -> pd.DataFrame:
    """
    Detecta anomalias (outliers) na coluna 'valor_total_num' usando Isolation Forest.
    """
    if df.empty or 'valor_total_num' not in df.columns:
        return pd.DataFrame()

    df_anomalia = df.copy()
    df_anomalia.dropna(subset=['valor_total_num'], inplace=True)
    
    # Precisa de mais de um dado para rodar a anomalia
    if len(df_anomalia) < 2:
        st.warning("√â necess√°rio mais de uma nota fiscal com valores v√°lidos para rodar o detector de anomalias.")
        return pd.DataFrame()

    # Preparar dados para o modelo (requer reshape para 2D)
    data = df_anomalia['valor_total_num'].values.astype(float).reshape(-1, 1)
    
    # Inicializar e treinar o modelo Isolation Forest
    # O par√¢metro 'contamination' √© a propor√ß√£o esperada de outliers (5% √© um bom chute inicial)
    model = IsolationForest(
        contamination=0.05, 
        random_state=42, 
        n_estimators=100
    )
    
    # O modelo retorna -1 para anomalias (outliers) e 1 para observa√ß√µes normais
    df_anomalia['anomaly_score'] = model.fit_predict(data)
    
    # Filtrar apenas as anomalias
    anomalies = df_anomalia[df_anomalia['anomaly_score'] == -1].sort_values(
        by='valor_total_num', ascending=False
    ).reset_index(drop=True)
    
    # Calcular o Z-Score para contextualizar a anomalia (qu√£o longe da m√©dia est√°)
    media = df_anomalia['valor_total_num'].mean()
    std = df_anomalia['valor_total_num'].std()
    
    if std > 0:
        anomalies['Z-Score'] = (anomalies['valor_total_num'] - media) / std
    else:
        anomalies['Z-Score'] = 0.0 # Evitar divis√£o por zero
        
    # Colunas de interesse no resultado
    anomalies_output = anomalies[[
        'data_emissao', 'emitente_nome', 'numero_nf', 'valor_total_num', 'Z-Score'
    ]].rename(columns={
        'valor_total_num': 'Valor Total (R$)'
    })
    
    anomalies_output['Valor Total (R$)'] = anomalies_output['Valor Total (R$)'].map('R$ {:,.2f}'.format)
    anomalies_output['Z-Score'] = anomalies_output['Z-Score'].map('{:.2f}'.format)

    return anomalies_output


# =============== 3. INTEGRA√á√ÉO COM STREAMLIT ===============

# Fun√ß√£o auxiliar para classifica√ß√£o por item (adaptada, focada em fallback)
def processar_e_exibir_classificacao_por_item(df: pd.DataFrame):
    """
    Processa a classifica√ß√£o focando na descri√ß√£o geral ou no primeiro item como fallback.
    """
    
    st.markdown("A classifica√ß√£o detalhada por item falhou (dados de item n√£o encontrados).")
    st.markdown("Usando a **Descri√ß√£o Principal/Emitente** como **Fallback**.")
    st.markdown("---")
    
    # Criar uma coluna de descri√ß√£o para fallback (prioriza o emitente)
    df_class = df.copy()
    df_class.dropna(subset=['emitente_nome'], inplace=True)
    
    if df_class.empty:
        st.warning("N√£o h√° notas com nome do emitente v√°lido para classifica√ß√£o fallback.")
        return

    # Limita o processamento a 100 notas por quest√£o de performance
    df_sample = df_class.head(100)
    
    resultados_classificacao = []
    
    with st.spinner(f"Classificando {len(df_sample)} Notas Fiscais por nome do Emitente (Fallback)..."):
        for index, row in df_sample.iterrows():
            descricao = row['emitente_nome'] # Usa o nome do fornecedor
            valor = row.get('valor_total_num', 0.0)
            
            resultado_ia = classify_expense_hf(descricao)
            
            if resultado_ia['status'] == 'OK':
                resultados_classificacao.append({
                    'Emitente': descricao,
                    'NF N√∫mero': row['numero_nf'],
                    'Valor (R$)': f"{valor:.2f}",
                    'Categoria Principal': resultado_ia['categoria'],
                    'Confian√ßa': f"{resultado_ia['confianca']:.1%}"
                })
            else:
                 resultados_classificacao.append({
                    'Emitente': descricao,
                    'NF N√∫mero': row['numero_nf'],
                    'Valor (R$)': f"{valor:.2f}",
                    'Categoria Principal': 'N√£o Classificado',
                    'Confian√ßa': '0%'
                })
    
    if resultados_classificacao:
        df_resultados = pd.DataFrame(resultados_classificacao)
        st.dataframe(df_resultados, use_container_width=True)


def add_ia_to_streamlit(df: pd.DataFrame) -> None:
    
    # Aplicar coer√ß√£o de tipo fora do fluxo principal
    df['valor_total_num'] = pd.to_numeric(df['valor_total_num'], errors='coerce')
    
    st.divider()
    st.subheader("ü§ñ An√°lise com Intelig√™ncia Artificial")
    
    tab1, tab2, tab3, tab4 = st.tabs([
        "Classifica√ß√£o (Fallback)",
        "Anomalias de Valor", 
        "Risco de Fornecedores",
        "Previs√£o de Gastos"
    ])
    
    # TAB 1: Classifica√ß√£o (Fallback)
    with tab1:
        st.markdown("### Classifica√ß√£o Agregada (Fallback)")
        processar_e_exibir_classificacao_por_item(df)

    # TAB 2: Detec√ß√£o de Anomalias (NOVO)
    with tab2:
        st.markdown("### üö® Detec√ß√£o de Anomalias de Valor (Outliers)")
        st.info("Utiliza o modelo Isolation Forest para identificar Notas Fiscais com valores muito acima ou abaixo do padr√£o hist√≥rico, que podem indicar erros ou fraudes.")
        
        anomalies_df = detect_anomalies_isolation_forest(df)
        
        if anomalies_df.empty:
            st.success("Nenhuma anomalia significativa detectada nos valores totais das Notas Fiscais.")
        else:
            st.warning(f"Foram detectadas **{len(anomalies_df)}** Notas Fiscais com valores an√¥malos (outliers):")
            st.dataframe(anomalies_df, use_container_width=True)

    # TAB 3: An√°lise de Risco de Fornecedores
    with tab3:
        st.markdown("### üõ°Ô∏è An√°lise de Risco de Fornecedores")
        st.info("O risco √© simulado. Para um resultado real, seria necess√°rio integrar uma API externa (Receita Federal, Serasa, etc.) com base no CNPJ.")
        
        # Simula a an√°lise de risco para cada fornecedor √∫nico
        fornecedores_unicos = df['emitente_doc'].dropna().unique()
        if len(fornecedores_unicos) > 0:
            risco_data = []
            for cnpj in fornecedores_unicos[:20]: # Limita para visualiza√ß√£o
                nome = df[df['emitente_doc'] == cnpj]['emitente_nome'].iloc[0] if len(df[df['emitente_doc'] == cnpj]['emitente_nome']) > 0 else "Nome Desconhecido"
                risco = analyze_supplier_risk(cnpj)
                
                risco_data.append({
                    'Fornecedor': nome,
                    'CNPJ': cnpj,
                    'N√≠vel de Risco': risco['risco_nivel'],
                    'Score de Risco': risco['risco_score']
                })
            
            df_risco = pd.DataFrame(risco_data)
            st.dataframe(df_risco, use_container_width=True)
        else:
            st.warning("Nenhum CNPJ de fornecedor encontrado para an√°lise de risco.")

    # TAB 4: Previs√£o de Gastos
    with tab4:
        st.markdown("### üîÆ Previs√£o de Gastos Futuros")
        st.info("Previs√£o simples baseada na m√©dia m√≥vel dos √∫ltimos meses.")
        
        df_forecast = simple_forecast(df)
        
        if df_forecast.empty:
            st.error("Dados insuficientes (menos de 3 meses) ou inv√°lidos para realizar a previs√£o.")
        else:
            st.markdown("#### Proje√ß√£o para os Pr√≥ximos 3 Meses")
            st.dataframe(df_forecast, use_container_width=True)
            
            # Adiciona um gr√°fico simples (opcional)
            st.bar_chart(df_forecast.set_index('M√™s')['Valor Previsto (R$)'].str.replace('R$ ', '').str.replace(',', '').astype(float))